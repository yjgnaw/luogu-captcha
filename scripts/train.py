"""Training script for the Luogu captcha CRNN.

Expected data layout (generated by `generate.php`):
  captchas/
    labels.csv   # filename,text
    captcha_00001.jpg
    ...

This script trains the CRNN with CTC loss. It supports a simple train/val split
from the same CSV and reports per-epoch loss and string-level accuracy.
"""

from __future__ import annotations

import argparse
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import List, Optional, Sequence, Tuple

import pandas as pd
import torch
from PIL import Image
from torch import Tensor, nn
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
from tqdm import tqdm

# Allow importing src modules when running from the repository root or scripts/
ROOT = Path(__file__).resolve().parents[1]
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))

from src.config import BLANK_INDEX, CHARSET, NUM_CLASSES  # noqa: E402
from src.model import CRNN, CRNNConfig, ctc_greedy_decode, text_to_labels  # noqa: E402


@dataclass
class Args:
    data_dir: Path
    labels_csv: Path
    batch_size: int
    epochs: int
    lr: float
    weight_decay: float
    num_workers: int
    device: str
    val_split: float
    save_path: Path
    img_channels: int
    seed: int
    resume: Optional[Path]


class CaptchaDataset(Dataset[Tuple[Tensor, str]]):
    def __init__(
        self,
        data_dir: Path,
        labels_csv: Path,
        transform=None,
        img_channels: int = 3,
        samples: Optional[List[Tuple[Path, str]]] = None,
    ):
        self.data_dir = data_dir
        self.transform = transform
        self.img_channels = img_channels

        if samples is None:
            df = pd.read_csv(labels_csv, header=None, names=["filename", "text"])
            self.samples: List[Tuple[Path, str]] = [
                (data_dir / row.filename, str(row.text))
                for row in df.itertuples(index=False)
            ]
        else:
            self.samples = samples

    def __len__(self) -> int:  # pragma: no cover - trivial
        return len(self.samples)

    def __getitem__(self, idx: int) -> Tuple[Tensor, str]:
        path, text = self.samples[idx]
        with Image.open(path) as img:
            if self.img_channels == 1:
                img = img.convert("L")
            else:
                img = img.convert("RGB")

            if self.transform:
                img = self.transform(img)
            else:
                img = transforms.ToTensor()(img)

        return img, text


def set_seed(seed: int) -> None:
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)


def collate_fn(batch: Sequence[Tuple[Tensor, str]]):
    images, texts = zip(*batch)
    images = torch.stack(images, dim=0)
    return images, list(texts)


def _load_samples(data_dir: Path, labels_csv: Path) -> List[Tuple[Path, str]]:
    df = pd.read_csv(labels_csv, header=None, names=["filename", "text"])
    return [
        (data_dir / row.filename, str(row.text)) for row in df.itertuples(index=False)
    ]


def build_loaders(args: Args):
    if not 0 < args.val_split < 1:
        raise ValueError("val_split must be in (0,1)")

    samples = _load_samples(args.data_dir, args.labels_csv)
    total = len(samples)
    val_size = max(1, int(total * args.val_split))
    train_size = total - val_size

    g = torch.Generator().manual_seed(args.seed)
    perm = torch.randperm(total, generator=g).tolist()
    val_indices = set(perm[:val_size])

    train_samples = [s for i, s in enumerate(samples) if i not in val_indices]
    val_samples = [s for i, s in enumerate(samples) if i in val_indices]

    train_transform = transforms.Compose(
        [
            transforms.ColorJitter(brightness=0.2, contrast=0.2),
            transforms.RandomAffine(degrees=5, translate=(0.02, 0.05), shear=5),
            transforms.ToTensor(),
        ]
    )
    val_transform = transforms.ToTensor()

    train_ds = CaptchaDataset(
        args.data_dir,
        args.labels_csv,
        transform=train_transform,
        img_channels=args.img_channels,
        samples=train_samples,
    )
    val_ds = CaptchaDataset(
        args.data_dir,
        args.labels_csv,
        transform=val_transform,
        img_channels=args.img_channels,
        samples=val_samples,
    )

    loader_kwargs = dict(
        batch_size=args.batch_size,
        num_workers=args.num_workers,
        pin_memory=torch.cuda.is_available() and args.device.startswith("cuda"),
        collate_fn=collate_fn,
        shuffle=True,
    )
    train_loader = DataLoader(train_ds, **loader_kwargs)
    val_loader = DataLoader(val_ds, **{**loader_kwargs, "shuffle": False})
    return train_loader, val_loader


def prepare_targets(
    texts: Sequence[str], device: torch.device
) -> Tuple[Tensor, Tensor]:
    label_tensors = [text_to_labels(t, device=device) for t in texts]
    targets = torch.cat(label_tensors)
    target_lengths = torch.tensor(
        [lt.numel() for lt in label_tensors], device=device, dtype=torch.long
    )
    return targets, target_lengths


def train_one_epoch(
    model: CRNN,
    loader: DataLoader,
    criterion: nn.CTCLoss,
    optimizer: torch.optim.Optimizer,
    device: torch.device,
) -> Tuple[float, float]:
    model.train()
    total_loss = 0.0
    total_samples = 0
    correct = 0

    for images, texts in tqdm(loader, desc="Train", leave=False):
        images = images.to(device)
        targets, target_lengths = prepare_targets(texts, device)
        batch_size = images.size(0)
        input_lengths = torch.full(
            size=(batch_size,),
            fill_value=model.output_lengths([images.shape[-1]])[0],
            dtype=torch.long,
            device=device,
        )

        optimizer.zero_grad()
        log_probs = model(images)
        loss = criterion(log_probs, targets, input_lengths, target_lengths)
        loss.backward()
        optimizer.step()

        total_loss += loss.item() * batch_size
        total_samples += batch_size

        decoded = ctc_greedy_decode(log_probs.detach(), charset=CHARSET)
        for pred, target in zip(decoded, texts):
            if pred == target:
                correct += 1

    avg_loss = total_loss / max(1, total_samples)
    acc = correct / max(1, total_samples)
    return avg_loss, acc


def evaluate(
    model: CRNN,
    loader: DataLoader,
    criterion: nn.CTCLoss,
    device: torch.device,
) -> Tuple[float, float]:
    model.eval()
    total_loss = 0.0
    total_samples = 0
    correct = 0

    with torch.no_grad():
        for images, texts in tqdm(loader, desc="Val", leave=False):
            images = images.to(device)
            targets, target_lengths = prepare_targets(texts, device)
            batch_size = images.size(0)
            input_lengths = torch.full(
                size=(batch_size,),
                fill_value=model.output_lengths([images.shape[-1]])[0],
                dtype=torch.long,
                device=device,
            )

            log_probs = model(images)
            loss = criterion(log_probs, targets, input_lengths, target_lengths)

            total_loss += loss.item() * batch_size
            total_samples += batch_size

            decoded = ctc_greedy_decode(log_probs, charset=CHARSET)
            for pred, target in zip(decoded, texts):
                if pred == target:
                    correct += 1

    avg_loss = total_loss / max(1, total_samples)
    acc = correct / max(1, total_samples)
    return avg_loss, acc


def parse_args() -> Args:
    parser = argparse.ArgumentParser(description="Train CRNN on Luogu captchas")
    parser.add_argument(
        "--data-dir",
        type=Path,
        default=ROOT / "captchas",
        help="Directory with captcha images",
    )
    parser.add_argument(
        "--labels-csv",
        type=Path,
        default=ROOT / "captchas" / "labels.csv",
        help="CSV with filename,text",
    )
    parser.add_argument("--batch-size", type=int, default=64)
    parser.add_argument("--epochs", type=int, default=5)
    parser.add_argument("--lr", type=float, default=1e-3)
    parser.add_argument("--weight-decay", type=float, default=1e-4)
    parser.add_argument("--num-workers", type=int, default=2)
    parser.add_argument(
        "--device", type=str, default="cuda" if torch.cuda.is_available() else "cpu"
    )
    parser.add_argument("--val-split", type=float, default=0.1)
    parser.add_argument(
        "--save-path", type=Path, default=ROOT / "checkpoints" / "crnn.pt"
    )
    parser.add_argument("--img-channels", type=int, default=3, choices=[1, 3])
    parser.add_argument("--seed", type=int, default=42)
    parser.add_argument(
        "--resume", type=Path, default=None, help="Path to checkpoint to resume from"
    )
    parsed = parser.parse_args()

    return Args(
        data_dir=parsed.data_dir,
        labels_csv=parsed.labels_csv,
        batch_size=parsed.batch_size,
        epochs=parsed.epochs,
        lr=parsed.lr,
        weight_decay=parsed.weight_decay,
        num_workers=parsed.num_workers,
        device=parsed.device,
        val_split=parsed.val_split,
        save_path=parsed.save_path,
        img_channels=parsed.img_channels,
        seed=parsed.seed,
        resume=parsed.resume,
    )


def load_checkpoint(
    ckpt_path: Path,
    model: CRNN,
    optimizer: torch.optim.Optimizer,
    device: torch.device,
) -> Tuple[int, float]:
    ckpt = torch.load(ckpt_path, map_location=device)
    model.load_state_dict(ckpt["model_state"])
    if "optimizer_state" in ckpt:
        optimizer.load_state_dict(ckpt["optimizer_state"])
    best_val_acc = float(ckpt.get("best_val_acc", 0.0))
    start_epoch = int(ckpt.get("epoch", 0)) + 1
    print(
        f"Resumed from {ckpt_path} (epoch={start_epoch-1}, best_val_acc={best_val_acc:.4f})"
    )
    return start_epoch, best_val_acc


def main() -> None:
    args = parse_args()
    set_seed(args.seed)

    device = torch.device(args.device)
    args.save_path.parent.mkdir(parents=True, exist_ok=True)

    train_loader, val_loader = build_loaders(args)

    model = CRNN(CRNNConfig(img_channels=args.img_channels)).to(device)
    criterion = nn.CTCLoss(blank=BLANK_INDEX, zero_infinity=True)
    optimizer = torch.optim.Adam(
        model.parameters(), lr=args.lr, weight_decay=args.weight_decay
    )

    start_epoch = 1
    best_val_acc = 0.0
    if args.resume is not None and args.resume.exists():
        start_epoch, best_val_acc = load_checkpoint(
            args.resume, model, optimizer, device
        )

    total_epochs = start_epoch + args.epochs - 1

    for epoch in range(start_epoch, start_epoch + args.epochs):
        print(f"Epoch {epoch}/{total_epochs}")
        train_loss, train_acc = train_one_epoch(
            model, train_loader, criterion, optimizer, device
        )
        val_loss, val_acc = evaluate(model, val_loader, criterion, device)

        print(
            f"  train_loss={train_loss:.4f} train_acc={train_acc:.4f} "
            f"val_loss={val_loss:.4f} val_acc={val_acc:.4f}"
        )

        if val_acc >= best_val_acc:
            best_val_acc = val_acc
            torch.save(
                {
                    "model_state": model.state_dict(),
                    "optimizer_state": optimizer.state_dict(),
                    "best_val_acc": best_val_acc,
                    "epoch": epoch,
                    "config": {
                        "img_channels": args.img_channels,
                        "charset": CHARSET,
                    },
                },
                args.save_path,
            )
            print(f"  Saved best model to {args.save_path} (val_acc={val_acc:.4f})")

    print("Training complete.")


if __name__ == "__main__":
    main()
